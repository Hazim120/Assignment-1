{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bdaf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Tokens - Non-news parts: 131\n",
      "[DEBUG] Tokens - News summaries combined: 264\n",
      "[DEBUG] Tokens - Total prompt with news: 395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4806/3813210151.py:239: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  mlflow.log_dict(sentiment_profile.dict(), \"sentiment_profile.json\")\n",
      "/tmp/ipykernel_4806/3813210151.py:242: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  return sentiment_profile.dict()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run sentiment-Google at: http://20.75.92.162:5000/#/experiments/477038078762324239/runs/1fa3826b3d2146eba877b4c3975dcaa1\n",
      "ðŸ§ª View experiment at: http://20.75.92.162:5000/#/experiments/477038078762324239\n",
      "âœ… Sentiment Profile:\n",
      "{'company_name': 'Google', 'stock_code': 'GOOG', 'newsdesc': [\"Google Pixel 10 review: perfectly fine. Asking the Pixel 10 to be more than what it is feels greedy. Google's non-Pro Pixel is priced fairly at 799, which is significantly less than the 999 Pixel 10 Pro. It comes with some handy upgrades, like Qi2 charging with built-in magnets.\", 'Google finally details Gemini usage limits. Until very recently it wasn t clear what usage limits were placed on Gemini at the various tiers. Thankfully Google has finally updated its Help Center article detailing Gemini Apps limits upgrades for Google AI subscribers. Gone are the useless descripto', 'Yes, Google Meet Is Down. \"Our engineering team continues to investigate the issue.\"', 'First look at the Google Home app powered by Gemini. Following the announcement that it is bringing Gemini to its Google Home smart home platform, it appears the company is updating its Google Home app to incorporate the new features. Android Authority dove into code for the upcoming v3.41.50.3 version of the a', 'Google is building a Duolingo rival into the Translate app. Google is putting AI-powered language learning tools into its Translate app. The new feature, rolling out now in beta, can create customized language lessons based on your skill level and your purpose for picking up a new language, such as vacationing in anot'], 'sentiment': 'Neutral', 'people_names': [], 'places_names': [], 'other_companies_referred': ['Duolingo'], 'related_industries': ['Consumer Electronics', 'Artificial Intelligence', 'Software', 'Language Learning', 'Telecommunications'], 'market_implications': \"Mixed signals. The Pixel 10 review is lukewarm, indicating potential stagnation in Google's hardware division. Detailing Gemini usage limits brings clarity, which is positive. The Google Meet outage is a negative, while the Gemini integration into Google Home and the Duolingo competitor in Translate are potential growth areas. Overall, the market may see this as Google exploring new avenues while facing some challenges in existing products.\", 'confidence_score': 0.75}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import mlflow\n",
    "import tiktoken\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIGURE MLflow & Vertex AI\n",
    "# ----------------------------\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://20.75.92.162:5000/\")\n",
    "mlflow.set_experiment(\"market-sentiment-analyzer\")\n",
    "\n",
    "llm = init_chat_model(\"gemini-2.0-flash\", model_provider=\"google_genai\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Token utils\n",
    "# ----------------------------\n",
    "\n",
    "def count_tokens(text: str, model_name: str = \"gemini-2.0-flash\") -> int:\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    return len(tokens)\n",
    "\n",
    "def truncate_text_by_tokens(text: str, max_tokens: int, model_name: str = \"gemini-2.0-flash\") -> str:\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model_name)\n",
    "    except KeyError:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    tokens = encoding.encode(text)\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return text\n",
    "    truncated_tokens = tokens[:max_tokens]\n",
    "    truncated_text = encoding.decode(truncated_tokens)\n",
    "    return truncated_text\n",
    "\n",
    "def clean_and_truncate_news(raw_news: str, max_tokens: int = 5000) -> str:\n",
    "    # Remove URLs, emails, excessive whitespace, etc.\n",
    "    text = raw_news\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s.,;:\\'\\\"-]', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    truncated = truncate_text_by_tokens(text, max_tokens)\n",
    "    return truncated\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Step 1. Get Stock Code\n",
    "# ----------------------------\n",
    "\n",
    "def get_stock_code(company_name: str) -> str:\n",
    "    url = f\"https://query1.finance.yahoo.com/v1/finance/search?q={company_name}&lang=en-US&region=US\"\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Yahoo error: {resp.status_code}: {resp.text}\")\n",
    "\n",
    "    data = resp.json()\n",
    "    try:\n",
    "        return data[\"quotes\"][0][\"symbol\"]\n",
    "    except Exception as e:\n",
    "        raise Exception(\"Unable to extract stock code\") from e\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Step 2. Fetch & Summarize News Using NewsAPI.org\n",
    "# ----------------------------\n",
    "\n",
    "def fetch_company_news(company_name: str, api_key: str, max_articles=5) -> str:\n",
    "    url = (\n",
    "        f\"https://newsapi.org/v2/everything?\"\n",
    "        f\"q={company_name}&\"\n",
    "        f\"language=en&\"\n",
    "        f\"sortBy=relevance&\"\n",
    "        f\"pageSize={max_articles}&\"\n",
    "        f\"apiKey={api_key}\"\n",
    "    )\n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "    resp = requests.get(url, headers=headers)\n",
    "\n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"News API error: {resp.status_code} - {resp.text}\")\n",
    "\n",
    "    articles = resp.json().get(\"articles\", [])\n",
    "    news_list = [f\"{article.get('title', '')}. {article.get('description', '')}\" for article in articles]\n",
    "    raw_news = \"\\n\".join(news_list)\n",
    "\n",
    "    return clean_and_truncate_news(raw_news, max_tokens=5000)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Step 3. Define Output Format Model\n",
    "# ----------------------------\n",
    "\n",
    "class SentimentProfile(BaseModel):\n",
    "    company_name: str\n",
    "    stock_code: str\n",
    "    newsdesc: List[str]\n",
    "    sentiment: str\n",
    "    people_names: List[str]\n",
    "    places_names: List[str]\n",
    "    other_companies_referred: List[str]\n",
    "    related_industries: List[str]\n",
    "    market_implications: str\n",
    "    confidence_score: float\n",
    "\n",
    "parser = PydanticOutputParser(pydantic_object=SentimentProfile)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Step 4. LangChain Prompt Template with manual small format instructions\n",
    "# ----------------------------\n",
    "\n",
    "simple_format_instructions = \"\"\"\n",
    "Respond ONLY in valid JSON with the following fields:\n",
    "- company_name (string)\n",
    "- stock_code (string)\n",
    "- newsdesc (list of strings)\n",
    "- sentiment (string: Positive, Negative, or Neutral)\n",
    "- people_names (list of strings)\n",
    "- places_names (list of strings)\n",
    "- other_companies_referred (list of strings)\n",
    "- related_industries (list of strings)\n",
    "- market_implications (string)\n",
    "- confidence_score (float between 0 and 1)\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "Analyze the following news for company sentiment and details.\n",
    "\n",
    "Company: {company_name}\n",
    "Stock Code: {stock_code}\n",
    "News Summary: {news_summaries}\n",
    "\n",
    "Please respond in this structured format:\n",
    "{format_instructions}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_name\", \"stock_code\", \"news_summaries\"],\n",
    "    partial_variables={\"format_instructions\": simple_format_instructions}\n",
    ")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Debug token counts before LLM call\n",
    "# ----------------------------\n",
    "\n",
    "def debug_token_counts(company_name, stock_code, news_summaries, prompt_template):\n",
    "    prompt_without_news = prompt_template.template.format(\n",
    "        company_name=company_name,\n",
    "        stock_code=stock_code,\n",
    "        news_summaries=\"\",\n",
    "        format_instructions=simple_format_instructions,\n",
    "    )\n",
    "    tokens_non_news = count_tokens(prompt_without_news)\n",
    "    \n",
    "    tokens_news = count_tokens(news_summaries)\n",
    "    \n",
    "    total_tokens = count_tokens(prompt_template.template.format(\n",
    "        company_name=company_name,\n",
    "        stock_code=stock_code,\n",
    "        news_summaries=news_summaries,\n",
    "        format_instructions=simple_format_instructions,\n",
    "    ))\n",
    "\n",
    "    #print(f\"[DEBUG] Tokens - Non-news parts: {tokens_non_news}\")\n",
    "    #print(f\"[DEBUG] Tokens - News summaries combined: {tokens_news}\")\n",
    "    #print(f\"[DEBUG] Tokens - Total prompt with news: {total_tokens}\")\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Step 5. Main pipeline function\n",
    "# ----------------------------\n",
    "\n",
    "def analyze_company(company_name: str, news_api_key: str) -> dict:\n",
    "    with mlflow.start_run(run_name=f\"sentiment-{company_name}\"):\n",
    "        mlflow.log_param(\"company_name\", company_name)\n",
    "\n",
    "        stock_code = get_stock_code(company_name)\n",
    "        mlflow.log_param(\"stock_code\", stock_code)\n",
    "\n",
    "        news_summary = fetch_company_news(company_name, news_api_key)\n",
    "        mlflow.log_text(news_summary, \"news_summary.txt\")\n",
    "\n",
    "        # Debug token counts\n",
    "        debug_token_counts(company_name, stock_code, news_summary, prompt_template)\n",
    "\n",
    "        # Prepare final prompt\n",
    "        final_prompt = prompt_template.format(\n",
    "            company_name=company_name,\n",
    "            stock_code=stock_code,\n",
    "            news_summaries=news_summary,\n",
    "        )\n",
    "\n",
    "        # Check final prompt tokens again and truncate if necessary\n",
    "        total_tokens = count_tokens(final_prompt)\n",
    "        max_allowed_tokens = 1048575  # Gemini max\n",
    "\n",
    "        if total_tokens > max_allowed_tokens:\n",
    "            # aggressively truncate news summary portion only\n",
    "            allowed_news_tokens = max_allowed_tokens - count_tokens(prompt_template.template.format(\n",
    "                company_name=company_name,\n",
    "                stock_code=stock_code,\n",
    "                news_summaries=\"\",\n",
    "                format_instructions=simple_format_instructions,\n",
    "            ))\n",
    "            truncated_news = truncate_text_by_tokens(news_summary, allowed_news_tokens)\n",
    "            final_prompt = prompt_template.format(\n",
    "                company_name=company_name,\n",
    "                stock_code=stock_code,\n",
    "                news_summaries=truncated_news,\n",
    "            )\n",
    "            #print(f\"[DEBUG] Truncated news summary to fit token limit. New token count: {count_tokens(final_prompt)}\")\n",
    "\n",
    "        # Run LLM\n",
    "        raw_output = llm.invoke(final_prompt)\n",
    "\n",
    "        # print(\"LLM Output:\\n\", raw_output.content)\n",
    "\n",
    "        # Parse output\n",
    "        sentiment_profile = parser.parse(raw_output.content)\n",
    "\n",
    "        # Log output\n",
    "        mlflow.log_dict(sentiment_profile.dict(), \"sentiment_profile.json\")\n",
    "        mlflow.log_metric(\"confidence_score\", sentiment_profile.confidence_score)\n",
    "\n",
    "        return sentiment_profile.dict()\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Run example\n",
    "# ----------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    company_name = input(\"Enter the company name: \").strip()\n",
    "    #news_api_key = os.getenv(\"NEWSAPI_KEY\") or input(\"Enter your NewsAPI.org API key: \").strip()\n",
    "    news_api_key='fe3fd9191a6147dd961d7207f4d0716d'\n",
    "    result = analyze_company(company_name, news_api_key)\n",
    "    print(\"âœ… Sentiment Profile:\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48602f94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
